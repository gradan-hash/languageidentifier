{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H42RdmerDHiQ"
      },
      "source": [
        "Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KYZEVpq0Wxi-",
        "outputId": "9536f2eb-f458-493f-fc42-67f26ac42b42"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "207/207 [==============================] - 28s 116ms/step - loss: 2.0864 - accuracy: 0.4591 - val_loss: 0.9776 - val_accuracy: 0.8368\n",
            "Epoch 2/50\n",
            "207/207 [==============================] - 10s 48ms/step - loss: 0.4259 - accuracy: 0.9619 - val_loss: 0.2954 - val_accuracy: 0.9698\n",
            "Epoch 3/50\n",
            "207/207 [==============================] - 10s 48ms/step - loss: 0.1071 - accuracy: 0.9944 - val_loss: 0.2042 - val_accuracy: 0.9710\n",
            "Epoch 4/50\n",
            "207/207 [==============================] - 9s 46ms/step - loss: 0.0451 - accuracy: 0.9980 - val_loss: 0.1708 - val_accuracy: 0.9704\n",
            "Epoch 5/50\n",
            "207/207 [==============================] - 11s 52ms/step - loss: 0.0237 - accuracy: 0.9988 - val_loss: 0.1555 - val_accuracy: 0.9686\n",
            "Epoch 6/50\n",
            "207/207 [==============================] - 10s 47ms/step - loss: 0.0147 - accuracy: 0.9989 - val_loss: 0.1451 - val_accuracy: 0.9692\n",
            "Epoch 7/50\n",
            "207/207 [==============================] - 11s 53ms/step - loss: 0.0101 - accuracy: 0.9991 - val_loss: 0.1388 - val_accuracy: 0.9686\n",
            "Epoch 8/50\n",
            "207/207 [==============================] - 11s 52ms/step - loss: 0.0077 - accuracy: 0.9991 - val_loss: 0.1360 - val_accuracy: 0.9680\n",
            "Epoch 9/50\n",
            "207/207 [==============================] - 11s 55ms/step - loss: 0.0062 - accuracy: 0.9991 - val_loss: 0.1350 - val_accuracy: 0.9655\n",
            "Epoch 10/50\n",
            "207/207 [==============================] - 11s 55ms/step - loss: 0.0053 - accuracy: 0.9991 - val_loss: 0.1287 - val_accuracy: 0.9674\n",
            "Epoch 11/50\n",
            "207/207 [==============================] - 11s 52ms/step - loss: 0.0047 - accuracy: 0.9991 - val_loss: 0.1263 - val_accuracy: 0.9680\n",
            "Epoch 12/50\n",
            "207/207 [==============================] - 9s 43ms/step - loss: 0.0040 - accuracy: 0.9991 - val_loss: 0.1311 - val_accuracy: 0.9661\n",
            "Epoch 13/50\n",
            "207/207 [==============================] - 11s 52ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.1275 - val_accuracy: 0.9674\n",
            "Epoch 14/50\n",
            "207/207 [==============================] - 11s 52ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.1393 - val_accuracy: 0.9625\n",
            "65/65 [==============================] - 1s 11ms/step\n",
            "Evaluation Metrics for MLP:\n",
            "Accuracy: 0.9743713733075435\n",
            "Precision: 0.9760084601459276\n",
            "Recall: 0.9743713733075435\n",
            "F1 Score: 0.9746678723490175\n",
            "\n",
            "Evaluation Metrics for SVM:\n",
            "Accuracy: 0.925531914893617\n",
            "Precision: 0.9471013470450899\n",
            "Recall: 0.925531914893617\n",
            "F1 Score: 0.9302167779900706\n",
            "\n",
            "Evaluation Metrics for Naive Bayes:\n",
            "Accuracy: 0.9279497098646035\n",
            "Precision: 0.9454426709374064\n",
            "Recall: 0.9279497098646035\n",
            "F1 Score: 0.929817778144432\n",
            "\n",
            "Evaluation Metrics for Random Forest:\n",
            "Accuracy: 0.9250483558994197\n",
            "Precision: 0.9385156019731358\n",
            "Recall: 0.9250483558994197\n",
            "F1 Score: 0.9274217802367858\n",
            "\n",
            "Evaluation Metrics for Logistic Regression:\n",
            "Accuracy: 0.9076402321083172\n",
            "Precision: 0.93878374310672\n",
            "Recall: 0.9076402321083172\n",
            "F1 Score: 0.9141610922914473\n",
            "\n",
            "Best Model (MLP): <keras.src.engine.sequential.Sequential object at 0x7f25961bd990>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "import joblib\n",
        "import pickle\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv(\"/content/Language Detection.csv\")\n",
        "\n",
        "# Function for text preprocessing\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    tokens = word_tokenize(text)\n",
        "    filtered_text = [word for word in tokens if word not in stop_words]\n",
        "    processed_text = \" \".join(filtered_text)\n",
        "    return processed_text\n",
        "\n",
        "# Apply preprocessing to the 'Text' column\n",
        "data['Processed_Text'] = data['Text'].apply(preprocess_text)\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X = tfidf_vectorizer.fit_transform(data['Processed_Text'])\n",
        "\n",
        "# Save the vectorizer\n",
        "with open('tfidf_vectorizer.pkl', 'wb') as f:\n",
        "    pickle.dump(tfidf_vectorizer, f)\n",
        "\n",
        "# Convert labels to numeric values\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(data['Language'])\n",
        "\n",
        "# Save the label encoder\n",
        "with open('label_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert sparse matrices to dense for MLP\n",
        "X_train_dense = X_train.toarray()\n",
        "X_test_dense = X_test.toarray()\n",
        "\n",
        "# Define the MLP model\n",
        "mlp_model = Sequential([\n",
        "    Dense(64, input_dim=X_train_dense.shape[1], activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(len(np.unique(y_train)), activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the MLP model\n",
        "mlp_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "# Train the MLP model\n",
        "mlp_history = mlp_model.fit(X_train_dense, y_train, epochs=50, batch_size=32, validation_split=0.2, callbacks=[early_stopping])\n",
        "\n",
        "# Evaluate the MLP model\n",
        "mlp_y_pred = np.argmax(mlp_model.predict(X_test_dense), axis=-1)\n",
        "mlp_accuracy = accuracy_score(y_test, mlp_y_pred)\n",
        "mlp_precision = precision_score(y_test, mlp_y_pred, average='weighted')\n",
        "mlp_recall = recall_score(y_test, mlp_y_pred, average='weighted')\n",
        "mlp_f1 = f1_score(y_test, mlp_y_pred, average='weighted')\n",
        "\n",
        "print(\"Evaluation Metrics for MLP:\")\n",
        "print(f\"Accuracy: {mlp_accuracy}\")\n",
        "print(f\"Precision: {mlp_precision}\")\n",
        "print(f\"Recall: {mlp_recall}\")\n",
        "print(f\"F1 Score: {mlp_f1}\")\n",
        "\n",
        "# Initialize other classifiers\n",
        "classifiers = {\n",
        "    \"SVM\": SVC(kernel='linear'),\n",
        "    \"Naive Bayes\": MultinomialNB(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"Logistic Regression\": LogisticRegression()\n",
        "}\n",
        "\n",
        "# Train and evaluate each classifier\n",
        "best_model = None\n",
        "best_accuracy = 0\n",
        "\n",
        "for name, classifier in classifiers.items():\n",
        "    classifier.fit(X_train, y_train)  # no need to convert to dense\n",
        "    y_pred = classifier.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"\\nEvaluation Metrics for {name}:\")\n",
        "    print(f\"Accuracy: {accuracy}\")\n",
        "    print(f\"Precision: {precision}\")\n",
        "    print(f\"Recall: {recall}\")\n",
        "    print(f\"F1 Score: {f1}\")\n",
        "\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_model = classifier\n",
        "\n",
        "# Check if MLP is the best model\n",
        "if mlp_accuracy > best_accuracy:\n",
        "    best_model = mlp_model\n",
        "    model_type = 'MLP'\n",
        "else:\n",
        "    model_type = 'Classifier'\n",
        "\n",
        "print(f\"\\nBest Model ({model_type}): {best_model}\")\n",
        "\n",
        "# Save the best model to a file\n",
        "if model_type == 'MLP':\n",
        "    mlp_model.save('best_model_mlp.h5')\n",
        "else:\n",
        "    joblib.dump(best_model, 'best_model_classifier.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "OZL6zQCOWCva",
        "outputId": "1ba35236-310d-42ed-ccc4-1effbc9a7529"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_07d3e844-93af-4fd8-af4a-a9db795bff09\", \"best_model_mlp.h5\", 35355920)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_aaa874ed-b3a1-4da7-b8a1-cae359035f9d\", \"label_encoder.pkl\", 406)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_b9b70510-2fc8-4dcc-9054-5562577d517b\", \"tfidf_vectorizer.pkl\", 1503201)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('/content/best_model_mlp.h5')\n",
        "files.download('/content/label_encoder.pkl')\n",
        "files.download('/content/tfidf_vectorizer.pkl')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGdbVAeUYtr5",
        "outputId": "9f57a375-e8fe-478d-bef2-6edd2db57108"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter a sentence to predict its language: Ciao Baby\n",
            "User Input (before preprocessing): Ciao Baby\n",
            "Processed Input: ciao baby\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "Predicted Language: Italian\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from keras.models import load_model\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Load the saved TF-IDF vectorizer\n",
        "with open('/content/tfidf_vectorizer.pkl', 'rb') as f:\n",
        "    tfidf_vectorizer = pickle.load(f)\n",
        "\n",
        "# Load the saved MLP model\n",
        "model = load_model('/content/best_model_mlp.h5')\n",
        "\n",
        "# Load the label encoder used during training\n",
        "with open('/content/label_encoder.pkl', 'rb') as f:\n",
        "    label_encoder = pickle.load(f)  # \n",
        "\n",
        "# Function for text preprocessing\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "    text = re.sub(r\"\\d+\", \"\", text)\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    tokens = word_tokenize(text)\n",
        "    filtered_text = [word for word in tokens if word not in stop_words]\n",
        "    processed_text = \" \".join(filtered_text)\n",
        "    return processed_text\n",
        "\n",
        "# Get input from the user\n",
        "user_input = input('Enter a sentence to predict its language: ')\n",
        "\n",
        "# Preprocess the user input\n",
        "print(\"User Input (before preprocessing):\", user_input)\n",
        "processed_input = preprocess_text(user_input)\n",
        "print(\"Processed Input:\", processed_input)\n",
        "\n",
        "# TF-IDF Vectorization\n",
        "X_input = tfidf_vectorizer.transform([processed_input])  # Transform the processed input\n",
        "\n",
        "# Convert the sparse matrix to a TensorFlow SparseTensor\n",
        "X_input_coo = X_input.tocoo()\n",
        "X_input_sparse_tensor = tf.sparse.SparseTensor(\n",
        "    indices=np.vstack((X_input_coo.row, X_input_coo.col)).T,\n",
        "    values=X_input_coo.data,\n",
        "    dense_shape=X_input_coo.shape\n",
        ")\n",
        "\n",
        "# Reorder the sparse tensor indices if necessary\n",
        "X_input_reordered = tf.sparse.reorder(X_input_sparse_tensor)\n",
        "\n",
        "# Predict the language index\n",
        "prediction = np.argmax(model.predict(X_input_reordered), axis=-1)\n",
        "\n",
        "# Map the predicted language index back to the original language label\n",
        "predicted_language = label_encoder.inverse_transform([prediction[0]])\n",
        "\n",
        "# Print the predicted language\n",
        "print(f'Predicted Language: {predicted_language[0]}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbZNVTlsjN44"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
